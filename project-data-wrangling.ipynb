{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 10000)\n",
    "pd.set_option('display.width', 1000)\n",
    "#Load Data\n",
    "master = pd.read_csv(r\"file1.csv\", low_memory=False)\n",
    "online = pd.read_csv(r\"file2.csv\", low_memory=False)\n",
    "outlook = pd.read_csv(r\"file3.csv\", low_memory=False, encoding = \"ISO-8859-1\")\n",
    "#Set Index\n",
    "master['id'] = master['record_id']\n",
    "master = master.set_index(['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select screening features we are interested in including in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master[[\n",
    "                 'record_id',\n",
    "                 'name',\n",
    "                 'email',\n",
    "                 'sex',\n",
    "                 'age',\n",
    "                 'years_edu',\n",
    "                 'employment',\n",
    "                 'monthly_income',\n",
    "                 'marital_status',\n",
    "                 'ethnicity',\n",
    "                 'race',\n",
    "                 'bmi',\n",
    "                 'vetstatus',\n",
    "                 'recruitment_method___1',\n",
    "                 'recruitment_method___2',\n",
    "                 'recruitment_method___3',\n",
    "                 'recruitment_method___4',             \n",
    "                 'recruitment_method___5',             \n",
    "                 'recruitment_method___6',             \n",
    "                 'recruitment_method___7',             \n",
    "                 'recruitment_method___8',             \n",
    "                 'recruitment_method___9',             \n",
    "                 'recruitment_method___10',            \n",
    "                 'recruitment_method___11',            \n",
    "                 'recruitment_method___12',            \n",
    "                 'recruitment_method___13',\n",
    "                 'recruitment_method___14',\n",
    "                 'recruitment_method___15',\n",
    "                 'smoker_status',\n",
    "                 'cigs_per_day',\n",
    "                 'alc_dep',\n",
    "                 'thc_dep',\n",
    "                 'stim_dep',\n",
    "                 'opiate_dep',\n",
    "                 'nic_dep',\n",
    "                 'coke_dep',\n",
    "                 'other_dep',\n",
    "                 'audit_score',\n",
    "                 ]]\n",
    "\n",
    "online = online[[\n",
    "                 'record_id',\n",
    "                 'name',\n",
    "                 'email',\n",
    "                 'sex',\n",
    "                 'age',\n",
    "                 'years_edu',\n",
    "                 'employment',\n",
    "                 'monthly_income',\n",
    "                 'marital_status',\n",
    "                 'ethnicity',\n",
    "                 'race',\n",
    "                 'bmi',\n",
    "                 'vetstatus',\n",
    "                 'recruitment_method___1',\n",
    "                 'recruitment_method___2',\n",
    "                 'recruitment_method___3',\n",
    "                 'recruitment_method___4',             \n",
    "                 'recruitment_method___5',             \n",
    "                 'recruitment_method___6',             \n",
    "                 'recruitment_method___7',             \n",
    "                 'recruitment_method___8',             \n",
    "                 'recruitment_method___9',             \n",
    "                 'recruitment_method___10',            \n",
    "                 'recruitment_method___11',            \n",
    "                 'recruitment_method___12',            \n",
    "                 'recruitment_method___13',\n",
    "                 'smoker_status',\n",
    "                 'cigs_per_day',\n",
    "                 'alc_dep_mild',\n",
    "                 'mj_dep_mod',\n",
    "                 'stim_dep_sev',\n",
    "                 'opiate_dep_sev',\n",
    "                 'nic_dep_sev',\n",
    "                 'coc_dep_sev',\n",
    "                 'other_dep_sev',\n",
    "                 'audit'\n",
    "                 ]]\n",
    "\n",
    "\n",
    "master = master.rename(columns = {\n",
    "                        'recruitment_method___1':'flyer', \n",
    "                        'recruitment_method___2':'radio_ad',\n",
    "                        'recruitment_method___3': 'website',\n",
    "                        'recruitment_method___4':'referral',\n",
    "                        'recruitment_method___5':'previously_participated',\n",
    "                        'recruitment_method___6':'craigslist',\n",
    "                        'recruitment_method___7':'email_bulletin',\n",
    "                        'recruitment_method___8':'other',\n",
    "                        'recruitment_method___9':'facebook_ad',\n",
    "                        'recruitment_method___10':'facebook_post',\n",
    "                        'recruitment_method___11':'newspaper',\n",
    "                        'recruitment_method___12':'bus_ad',\n",
    "                        'recruitment_method___13':'billboard_ad',\n",
    "                        'recruitment_method___14':'community_event',\n",
    "                        'recruitment_method___15':'web search'\n",
    "                        })\n",
    "\n",
    "\n",
    "\n",
    "online = online.rename(columns = {\n",
    "                        'recruitment_method___1':'flyer', \n",
    "                        'recruitment_method___2':'radio_ad',\n",
    "                        'recruitment_method___3': 'website',\n",
    "                        'recruitment_method___4':'referral',\n",
    "                        'recruitment_method___5':'previously_participated',\n",
    "                        'recruitment_method___6':'craigslist',\n",
    "                        'recruitment_method___7':'email_bulletin',\n",
    "                        'recruitment_method___8':'other',\n",
    "                        'recruitment_method___9':'facebook_ad',\n",
    "                        'recruitment_method___10':'facebook_post',\n",
    "                        'recruitment_method___11':'newspaper',\n",
    "                        'recruitment_method___12':'bus_ad',\n",
    "                        'recruitment_method___13':'billboard_ad',\n",
    "                        'audit':'audit_score', \n",
    "                        'alc_dep_mild':'alc_dep',\n",
    "                        'mj_dep_mod': 'thc_dep',\n",
    "                        'stim_dep_sev':'stim_dep',\n",
    "                        'opiate_dep_sev':'opiate_dep',\n",
    "                        'nic_dep_sev': 'nic_dep',\n",
    "                        'coc_dep_sev': 'coc_dep',\n",
    "                        'other_dep_sev': 'other_dep'\n",
    "                        })\n",
    "\n",
    "#Make lookup dictionaries\n",
    "sex_dict = {\n",
    "    1:'male',\n",
    "    0:'female'\n",
    "    }\n",
    "\n",
    "\n",
    "race_dict = {\n",
    "    0:'american indian',\n",
    "    1:'asian',\n",
    "    2:'hawaian',\n",
    "    3:'african american',\n",
    "    4:'white',\n",
    "    5:'more than one race',\n",
    "    6:'unknown',\n",
    "    7:'other'\n",
    "    }\n",
    "\n",
    "marital_dict = {    \n",
    "    1:'Never married',\n",
    "    2:'Married',\n",
    "    3:'Divorced',\n",
    "    4:'Separated',\n",
    "    5:'Widowed'\n",
    "    }\n",
    "\n",
    "employment_dict = {\n",
    "    1:'Full time',\n",
    "    2:'Part time',\n",
    "    3:'Unemployed'\n",
    "    }\n",
    "\n",
    "ethnicity_dict = {\n",
    "    0:'Hispanic',\n",
    "    1:'NOT Hispanic',\n",
    "    2:'Unknown'\n",
    "    }\n",
    "\n",
    "#Give categorical variables strings values so pd.get_dummies() works\n",
    "master['sex'] = master['sex'].apply(lambda x: sex_dict[x] if x in list(sex_dict.keys()) else x)\n",
    "master['employment'] = master['employment'].apply(lambda x: employment_dict[x] if x in list(employment_dict.keys()) else x)\n",
    "master['marital_status'] = master['marital_status'].apply(lambda x: marital_dict[x] if x in list(marital_dict.keys()) else x)\n",
    "master['ethnicity'] = master['ethnicity'].apply(lambda x: ethnicity_dict[x] if x in list(ethnicity_dict.keys()) else x)\n",
    "master['race'] = master['race'].apply(lambda x: race_dict[x] if x in list(race_dict.keys()) else x)\n",
    "\n",
    "online['sex'] = online['sex'].apply(lambda x: sex_dict[x] if x in list(sex_dict.keys()) else x)\n",
    "online['employment'] = online['employment'].apply(lambda x: employment_dict[x] if x in list(employment_dict.keys()) else x)\n",
    "online['marital_status'] = online['marital_status'].apply(lambda x: marital_dict[x] if x in list(marital_dict.keys()) else x)\n",
    "online['ethnicity'] = online['ethnicity'].apply(lambda x: ethnicity_dict[x] if x in list(ethnicity_dict.keys()) else x)\n",
    "online['race'] = online['race'].apply(lambda x: race_dict[x] if x in list(race_dict.keys()) else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some preliminary cleaning of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set all strings to lowercase for ease of string comparisons\n",
    "master = master.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "online = online.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "outlook = outlook.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "#Clean out empty records without a name\n",
    "online = online.dropna(subset=['name'])\n",
    "master = master.dropna(subset=['name'])\n",
    "#Record 'checked' and 'unchecked' to 1 and 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will start with cleaning the outlook data since that is the key to determining our target variable\n",
    "This data is quite messy and we need to make decisions about what to consider a true \"No Show\" and what other variables we can derive such as duration of appointment etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean out the straggling MRI scanning appointments, they are of no use\n",
    "outlook = outlook[outlook['Subject'].str.contains('scan') == False]\n",
    "#Split the subject variable to derive the participant ID and additional info\n",
    "outlook[['id', 'extra']] = outlook['Subject'].str.split('-', 1, expand=True)\n",
    "#Use Regex to search for values that follow the exact pattern of XX####\n",
    "outlook['id'] = outlook['id'].str.extract('(^\\S\\S\\d{4})')\n",
    "#Use Regex to extract the numerical values only from this string\n",
    "outlook['id'] = outlook['id'].str.extract('(\\d+)')\n",
    "#Strip any extra white space\n",
    "outlook['extra'] = outlook['extra'].str.strip()\n",
    "#Split the additional data string to derive the study number and session \n",
    "outlook[['study', 'session']] = outlook['extra'].str.split(' ', 1, expand=True)\n",
    "#Drop appointments without a participant ID\n",
    "outlook = outlook.dropna(subset=['id'])\n",
    "#Drop the appointments without a 'Categories' field, it is impossible to determine a result without it\n",
    "outlook = outlook.dropna(subset = ['Categories'])\n",
    "#Looking at only first(Consent) appointments for now\n",
    "outlook = outlook[outlook['Categories'].str.contains('consent')]\n",
    "#Not sure what to do with cancelled appointments, removing for now\n",
    "outlook = outlook[~outlook['Categories'].str.contains('cancel')]\n",
    "#Set id to data type int to prepare it for being called as the index\n",
    "outlook['temp_id'] = outlook['id'].astype('int')\n",
    "outlook['id'] = outlook['id'].astype('int')\n",
    "outlook = outlook.set_index(['temp_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to know which participants we will need to find REDCap data for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1524"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate a list of IDs for each appointment\n",
    "participants = list(outlook.id.unique())\n",
    "#Get the number of unique IDs in our appointment dataset\n",
    "len(participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the participants that we need and their screening data\n",
    "master = master.loc[participants]\n",
    "#Check that no record ID's are null values\n",
    "master.record_id.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh! We have null record ID's we will need to remove them from this dataset and also our outlook dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a list of the problem ID's\n",
    "problem_ids = list(master.loc[master['record_id'].isnull()].index)\n",
    "#Clean out these records with null ID's\n",
    "master = master.dropna(subset=['record_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean these out of our Outlook dataset as well, these ID's are problematic and clearly do not exist if they were not found in REDCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlook = outlook.loc[~outlook.id.isin(problem_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1515\n",
      "1515\n"
     ]
    }
   ],
   "source": [
    "#Quick double check\n",
    "print(len(list(outlook.id.unique())))\n",
    "print(len(master.record_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diving in deeper to REDCap Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little history about screening data... When a new participant is added to the master screen that 4 digit ID will be their participant ID for all studies. Online screenning data is too messy and erratic to let participants add new screens to our \"Master Record system\". Therefore an online screen was added as a seperate tool for intial screening and when a participant is scheduled, add them to the the Master REDCap. This is typically just barebones contact info that is entered. The problem is if the participant never comes in to do a study then their Master screen will remain incomplete. We really need as much of this info as possible for our model so we can try to harvest what info we can from completed online screens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to try joining on name and using the online screen data to fill in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122.23684210526316"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.isna().sum().mean()#Lots of missing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to prepare for and perform join on 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Get a dataframe from the online screen containing the same names\n",
    "onlinefill = online[online['name'].isin(master['name'])]\n",
    "#Preserve name in index\n",
    "onlinefill['temp_name'] = online['name']\n",
    "#Get a dataframe for just id and name to prepare for the join\n",
    "merge_df = master[['record_id', 'name']]\n",
    "#Preserve name in index\n",
    "merge_df['temp_name'] = merge_df['name']\n",
    "#Set index to name to prepare for the join\n",
    "merge_df = merge_df.set_index(['temp_name'])\n",
    "onlinefill = onlinefill.set_index(['temp_name'])\n",
    "#Join on name and set index to record_id\n",
    "joinfill = merge_df.join(onlinefill, how='left',lsuffix='_master', rsuffix='_online')\n",
    "joinfill['master_id'] = joinfill['record_id_master']\n",
    "joinfill['record_id_master'] = joinfill['record_id_master'].astype('int')\n",
    "joinfill = joinfill.set_index(['record_id_master'])\n",
    "#fill = merge_df.combine_first(onlinefill)\n",
    "#This looks like the ticket!!!\n",
    "danger = master.combine_first(joinfill)\n",
    "danger.drop_duplicates(subset=['record_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1515, 43)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "danger.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test to see how many values we might have gained... looks like across most features we gained 200+ more values. Not bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                        181.0\n",
       "alc_dep                      0.0\n",
       "audit_score                296.0\n",
       "billboard_ad                 0.0\n",
       "bmi                        211.0\n",
       "bus_ad                       0.0\n",
       "cigs_per_day               146.0\n",
       "coc_dep                      NaN\n",
       "coke_dep                     0.0\n",
       "community_event              0.0\n",
       "craigslist                   0.0\n",
       "email                       57.0\n",
       "email_bulletin               0.0\n",
       "employment                 197.0\n",
       "ethnicity                  194.0\n",
       "facebook_ad                  0.0\n",
       "facebook_post                0.0\n",
       "flyer                        0.0\n",
       "marital_status             206.0\n",
       "master_id                    NaN\n",
       "monthly_income             191.0\n",
       "name                         0.0\n",
       "name_master                  NaN\n",
       "name_online                  NaN\n",
       "newspaper                    0.0\n",
       "nic_dep                      0.0\n",
       "opiate_dep                   0.0\n",
       "other                        0.0\n",
       "other_dep                    0.0\n",
       "previously_participated      0.0\n",
       "race                       206.0\n",
       "radio_ad                     0.0\n",
       "record_id                    0.0\n",
       "record_id_online             NaN\n",
       "referral                     0.0\n",
       "sex                        119.0\n",
       "smoker_status              207.0\n",
       "stim_dep                     0.0\n",
       "thc_dep                      0.0\n",
       "vetstatus                  216.0\n",
       "web search                   0.0\n",
       "website                      0.0\n",
       "years_edu                  186.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.isna().sum()-danger.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                         28\n",
       "alc_dep                      0\n",
       "audit_score                525\n",
       "billboard_ad                 0\n",
       "bmi                        362\n",
       "bus_ad                       0\n",
       "cigs_per_day               429\n",
       "coc_dep                    707\n",
       "coke_dep                     0\n",
       "community_event              0\n",
       "craigslist                   0\n",
       "email                      315\n",
       "email_bulletin               0\n",
       "employment                  34\n",
       "ethnicity                   59\n",
       "facebook_ad                  0\n",
       "facebook_post                0\n",
       "flyer                        0\n",
       "marital_status              33\n",
       "master_id                    0\n",
       "monthly_income              65\n",
       "name                         0\n",
       "name_master                  0\n",
       "name_online                707\n",
       "newspaper                    0\n",
       "nic_dep                      0\n",
       "opiate_dep                   0\n",
       "other                        0\n",
       "other_dep                    0\n",
       "previously_participated      0\n",
       "race                        34\n",
       "radio_ad                     0\n",
       "record_id                    0\n",
       "record_id_online           707\n",
       "referral                     0\n",
       "sex                         15\n",
       "smoker_status               32\n",
       "stim_dep                     0\n",
       "thc_dep                      0\n",
       "vetstatus                   67\n",
       "web search                   0\n",
       "website                      0\n",
       "years_edu                   34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "danger.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "record_id                    0\n",
       "name                         0\n",
       "email                      372\n",
       "sex                        134\n",
       "age                        209\n",
       "years_edu                  220\n",
       "employment                 231\n",
       "monthly_income             256\n",
       "marital_status             239\n",
       "ethnicity                  253\n",
       "race                       240\n",
       "bmi                        573\n",
       "vetstatus                  283\n",
       "flyer                        0\n",
       "radio_ad                     0\n",
       "website                      0\n",
       "referral                     0\n",
       "previously_participated      0\n",
       "craigslist                   0\n",
       "email_bulletin               0\n",
       "other                        0\n",
       "facebook_ad                  0\n",
       "facebook_post                0\n",
       "newspaper                    0\n",
       "bus_ad                       0\n",
       "billboard_ad                 0\n",
       "community_event              0\n",
       "web search                   0\n",
       "smoker_status              239\n",
       "cigs_per_day               575\n",
       "alc_dep                      0\n",
       "thc_dep                      0\n",
       "stim_dep                     0\n",
       "opiate_dep                   0\n",
       "nic_dep                      0\n",
       "coke_dep                     0\n",
       "other_dep                    0\n",
       "audit_score                821\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.559444183006374"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.bmi.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use our temporary dataframe to fill in null values using data from the online screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace obvious outliers\n",
    "master['monthly_income'] = master['monthly_income'].apply(lambda x: 4000 if x > 35000 else x)\n",
    "\n",
    "master.at[3923,'bmi'] = 39.48\n",
    "master.at[4849,'bmi'] = 28.46\n",
    "master.at[2220,'bmi'] = 39.45\n",
    "master.at[3978,'bmi'] = 42.96\n",
    "master.at[4773,'bmi'] = 36.13\n",
    "master.at[3826,'bmi'] = 35.26\n",
    "\n",
    "#Fill missing values with the joined online data\n",
    "master = master.fillna(danger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1153.000000\n",
       "mean       29.657539\n",
       "std         7.815985\n",
       "min        15.188272\n",
       "25%        23.625289\n",
       "50%        28.286391\n",
       "75%        34.207396\n",
       "max        63.872106\n",
       "Name: bmi, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.bmi.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.28639053"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.bmi.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill some null values with 0\n",
    "master['audit_score'].fillna(0, inplace=True)\n",
    "master['cigs_per_day'].fillna(0, inplace=True)\n",
    "master['smoker_status'].fillna(0, inplace=True)\n",
    "master['vetstatus'].fillna(0, inplace=True)\n",
    "#Fill others with mean\n",
    "master['bmi'].fillna(master.bmi.mean(), inplace=True)\n",
    "master['age'].fillna(master.age.mean(), inplace=True)\n",
    "master['years_edu'].fillna(master.years_edu.mean(), inplace=True)\n",
    "\n",
    "#Fill income with median\n",
    "master['monthly_income'].fillna(master.monthly_income.median(), inplace=True)\n",
    "\n",
    "master.drop(labels = ['record_id','name', 'email'], axis=1, inplace=True )\n",
    "#One-hot encoding cat variables\n",
    "#encoded = pd.get_dummies(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>years_edu</th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>bmi</th>\n",
       "      <th>vetstatus</th>\n",
       "      <th>flyer</th>\n",
       "      <th>radio_ad</th>\n",
       "      <th>website</th>\n",
       "      <th>referral</th>\n",
       "      <th>previously_participated</th>\n",
       "      <th>craigslist</th>\n",
       "      <th>email_bulletin</th>\n",
       "      <th>other</th>\n",
       "      <th>facebook_ad</th>\n",
       "      <th>facebook_post</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>bus_ad</th>\n",
       "      <th>billboard_ad</th>\n",
       "      <th>community_event</th>\n",
       "      <th>web search</th>\n",
       "      <th>smoker_status</th>\n",
       "      <th>cigs_per_day</th>\n",
       "      <th>alc_dep</th>\n",
       "      <th>thc_dep</th>\n",
       "      <th>stim_dep</th>\n",
       "      <th>opiate_dep</th>\n",
       "      <th>nic_dep</th>\n",
       "      <th>coke_dep</th>\n",
       "      <th>other_dep</th>\n",
       "      <th>audit_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.00000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "      <td>1515.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.318090</td>\n",
       "      <td>13.071236</td>\n",
       "      <td>1135.251703</td>\n",
       "      <td>29.657539</td>\n",
       "      <td>0.071947</td>\n",
       "      <td>0.190759</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.037624</td>\n",
       "      <td>0.316172</td>\n",
       "      <td>0.071287</td>\n",
       "      <td>0.223762</td>\n",
       "      <td>0.040924</td>\n",
       "      <td>0.034983</td>\n",
       "      <td>0.022442</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.008581</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.00198</td>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.713531</td>\n",
       "      <td>13.609241</td>\n",
       "      <td>0.320792</td>\n",
       "      <td>0.156436</td>\n",
       "      <td>0.040264</td>\n",
       "      <td>0.058086</td>\n",
       "      <td>0.545875</td>\n",
       "      <td>0.145875</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>8.751815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.110307</td>\n",
       "      <td>2.311912</td>\n",
       "      <td>1318.575552</td>\n",
       "      <td>6.817844</td>\n",
       "      <td>0.258486</td>\n",
       "      <td>0.393029</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.190347</td>\n",
       "      <td>0.465134</td>\n",
       "      <td>0.257389</td>\n",
       "      <td>0.416902</td>\n",
       "      <td>0.198180</td>\n",
       "      <td>0.183799</td>\n",
       "      <td>0.148166</td>\n",
       "      <td>0.067839</td>\n",
       "      <td>0.051333</td>\n",
       "      <td>0.092265</td>\n",
       "      <td>0.036322</td>\n",
       "      <td>0.04447</td>\n",
       "      <td>0.051333</td>\n",
       "      <td>0.452260</td>\n",
       "      <td>12.120287</td>\n",
       "      <td>0.466935</td>\n",
       "      <td>0.363388</td>\n",
       "      <td>0.196643</td>\n",
       "      <td>0.233983</td>\n",
       "      <td>0.498055</td>\n",
       "      <td>0.353097</td>\n",
       "      <td>0.108387</td>\n",
       "      <td>10.450888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.188272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>25.056806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>29.657539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>32.058392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>63.872106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age    years_edu  monthly_income          bmi    vetstatus        flyer     radio_ad      website     referral  previously_participated   craigslist  email_bulletin        other  facebook_ad  facebook_post    newspaper       bus_ad  billboard_ad  community_event   web search  smoker_status  cigs_per_day      alc_dep      thc_dep     stim_dep   opiate_dep      nic_dep     coke_dep    other_dep  audit_score\n",
       "count  1515.000000  1515.000000     1515.000000  1515.000000  1515.000000  1515.000000  1515.000000  1515.000000  1515.000000              1515.000000  1515.000000     1515.000000  1515.000000  1515.000000    1515.000000  1515.000000  1515.000000   1515.000000       1515.00000  1515.000000    1515.000000   1515.000000  1515.000000  1515.000000  1515.000000  1515.000000  1515.000000  1515.000000  1515.000000  1515.000000\n",
       "mean     37.318090    13.071236     1135.251703    29.657539     0.071947     0.190759     0.006601     0.037624     0.316172                 0.071287     0.223762        0.040924     0.034983     0.022442       0.004620     0.002640     0.008581      0.001320          0.00198     0.002640       0.713531     13.609241     0.320792     0.156436     0.040264     0.058086     0.545875     0.145875     0.011881     8.751815\n",
       "std      12.110307     2.311912     1318.575552     6.817844     0.258486     0.393029     0.081003     0.190347     0.465134                 0.257389     0.416902        0.198180     0.183799     0.148166       0.067839     0.051333     0.092265      0.036322          0.04447     0.051333       0.452260     12.120287     0.466935     0.363388     0.196643     0.233983     0.498055     0.353097     0.108387    10.450888\n",
       "min      18.000000     0.000000        0.000000    15.188272     0.000000     0.000000     0.000000     0.000000     0.000000                 0.000000     0.000000        0.000000     0.000000     0.000000       0.000000     0.000000     0.000000      0.000000          0.00000     0.000000       0.000000      0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000\n",
       "25%      27.000000    12.000000      200.000000    25.056806     0.000000     0.000000     0.000000     0.000000     0.000000                 0.000000     0.000000        0.000000     0.000000     0.000000       0.000000     0.000000     0.000000      0.000000          0.00000     0.000000       0.000000      0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000     0.000000\n",
       "50%      36.000000    12.000000      800.000000    29.657539     0.000000     0.000000     0.000000     0.000000     0.000000                 0.000000     0.000000        0.000000     0.000000     0.000000       0.000000     0.000000     0.000000      0.000000          0.00000     0.000000       1.000000     12.000000     0.000000     0.000000     0.000000     0.000000     1.000000     0.000000     0.000000     4.000000\n",
       "75%      47.000000    14.000000     1500.000000    32.058392     0.000000     0.000000     0.000000     0.000000     1.000000                 0.000000     0.000000        0.000000     0.000000     0.000000       0.000000     0.000000     0.000000      0.000000          0.00000     0.000000       1.000000     20.000000     1.000000     0.000000     0.000000     0.000000     1.000000     0.000000     0.000000    16.000000\n",
       "max      66.000000    23.000000    12000.000000    63.872106     1.000000     1.000000     1.000000     1.000000     1.000000                 1.000000     1.000000        1.000000     1.000000     1.000000       1.000000     1.000000     1.000000      1.000000          1.00000     1.000000       1.000000     80.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000     1.000000    40.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that our screening data has been cleaned up a bit, join with outlook data so each appointment has associated screening values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = outlook.join(master, how='left',lsuffix='_outlook', rsuffix='_redcap')\n",
    "#Collapse categories indicating the participant \"showed\" for their appointment.\n",
    "df['target'] = df['Categories'].apply(lambda x: 1 if 'session run'in x or 'screen fail' in x or 'ineligible to enroll' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels= ['Subject',                         \n",
    "'Start Date',                      \n",
    "'Start Time',                      \n",
    "'End Date',                       \n",
    "'End Time',                       \n",
    "'All day event',                   \n",
    "'Reminder on/off',                 \n",
    "'Reminder Date',                  \n",
    "'Reminder Time',                   \n",
    "'Meeting Organizer',               \n",
    "'Required Attendees',              \n",
    "'Optional Attendees',              \n",
    "'Meeting Resources',               \n",
    "'Billing Information',             \n",
    "'Categories',                      \n",
    "'Description',                     \n",
    "'Location',                       \n",
    "'Mileage',                        \n",
    "'Priority',                        \n",
    "'Private',                         \n",
    "'Sensitivity',                     \n",
    "'Show time as',                    \n",
    "'id',                              \n",
    "'extra',                           \n",
    "'study',                           \n",
    "'session'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output data to file for future use.\n",
    "df.to_csv('Data_Combined_Cleaned_10.11.18_no_dummies.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
